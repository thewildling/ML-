# Managing data for CM4Smart :floppy_disk:

These python files are used to organize and format the data given by the machines in the CM¤Smart project. 
It uses several .py files, containing several methods to do this.

## Projectstructure :clipboard:

![alt text](https://github.com/anderf2706/CM4Smart/blob/master/docs/img/CM4Smart%20PS%20.png)

**Structure**

## Getting Started :checkered_flag:

To get started, download this repo either by cloning it from your IDE, or download it as a zip. 
There is several py-files in the repo, but everything you need to do, is located in analyseData.py. Here you
can find the majority og the methods used for structuring data. All running of the methods is also done here.

All the pkl-files needed to make dataframes for ML-training and testing is already generated in this repo, 
for the M1, M3, M58, M93. If you should need to generate the files again, this can be done(see running the system). 
As it uses a os-module to find root-folder, No new path should need to be changed. 

## Running the system :rocket:

All methodcalls are done at the bottom of the analyseData-file. The sort and sort_on_order is set to false from the start. 
If you change the 4 false in each to true, you generate the files found in the orders folder. To do this, you
should delete all files and folders in the orders-folder. These are the sensor-readings
structured properly, and either is sorted on date or on order-nr. The full 6M files are located under 
pickle_data->orders->machine-nr->at the bottom. The ones ordered on orders, are located in the same folder, but under the 
respective order-nr-folder. 


### Example of running system

![alt text](https://github.com/anderf2706/CM4Smart/blob/master/docs/img/example_running_code.png)

**Running methods in correct place**


## Methods :star:

methods from the top to bottom:

### Pickles(boolean generate):
used to call the method in the readingCSV. This generates the pkl-files used to generate the files in sort. 
Mainly what the method do is porting the csv files to pandas DataFrame, and change the date format, so it is equal on all.
This does not need to be run unless new machines are coming in. 
To use it, set generate to True, on line 19. It needs to be run here. 

### Sort(boolean generate_M1, boolean generate_M3, boolean generate_M58, boolean generate_M93):
collective method for generating the pkl-files into correct structure. This does not sort on order, and will give you the
full 6M. 

### Sort_on_order(boolean generate_M1, boolean generate_M3, boolean generate_M58, boolean generate_M93):
same as above, but runs the methods to index the sensor-data after order. This func need to be called after sort, because it uses files generated by
the sort method.

### savehtml(dataframe file, string nameoffile(only name, without .html)):
takes in a file in the from of a DataFrame, and returns a html-file. Used mostly for getting a easier overview over the data. Good at showing other what
the data contains. Saved in html-folder.

![alt text](https://github.com/anderf2706/CM4Smart/blob/master/docs/img/html-example.png)

**Example of what is generated**

### save_obj(dataframe/dict obj, string path):
saves a dataframe to pkl-format. This is good if you are going to use the file later, when it can be tedious to generate them every run. This is much faster,
and is what the sort and sort_on_order uses.

### load_obj(string path):
returns a dataframe of a pkl-file. This is used to retrieve the file saved by save_obj.

### makeReport(dataframe dataset, string name(only name, no.html)):
uses a module called pandas-profiling for generating a html-file showing a lot of info about the data. Input is the dataframe you want to look at. 
Name is the filename which it will be called. It is saved in the html-folder. Some have problems installing pandas-profiling. If this is the case, 
you can comment out the import on the top and the method. 

![alt text](https://github.com/anderf2706/CM4Smart/blob/master/docs/img/PP-1.png)

**First part of profile generated**

![alt text](https://github.com/anderf2706/CM4Smart/blob/master/docs/img/PP-2.png)

**Second part of profile generated**


### merge_NN(dataframe df1, dataframe df2, string on, string how, int headamount, string htmlname, string series(column of values)):
used to merge 2 different dataframes on a common denominator. used to compare values. df1 and df2 is the dataframes to merge. on is the common denominator.
how is how to merge. often use'left'. headamount is the amount of values to merge from top. Series is the string that tells the value. 'Value' for sensors. 
'ValueString' for downtime and status. 

### merge(dataframe df1, dataframe df2):
Same as above, but uses common denominator of Dates, and uses how=left. Easy way to merge on dates of different sensors. 

### strangeThings(dataframe sensor, string machine_nr):
used to check if a sensor is reading not null, when the status is set to STOPPED. Returns a list if there is numbers that are not null, else an empty list. 

### merge_machine_full_dataFrame(string machine):
merges every sensorreading and status into one dataframe, on the date. Need to have run the sort method first. Good for looking through the whole machines run.

### merge_on_order(int order):
does the same as the one above, but merges together all the machines that worked on the order that is inputed. Since this merges on date, and the machines doesn't
work during the same time, there will always be null values on the machine not active. 

### index_on_order(dataframe sensor, string name, string machine_nr):
#### This method is located in the sorting_methods.py file. This is done to clean up the code, since these 2 methods are very long.  
This is what is used during the sort_on_order func. This can be run by itself, if you only need to generate for one sensor. The name input needs to be either:
-'ASL'
-'ASRV'
-'ST'
-'FR'
-'FRO'
-'status'
-'downtime'

You need to check if the machine you have entered have this sensorreading. Machine-nr is just 'M1' etc.

### index_on_month(dataframe sensor, string name, string machine_nr):
#### This method is located in the sorting_methods.py file. This is done to clean up the code, since these 2 methods are very long. 
works the same as the one above, but doesn't index on order, but makes the full 6M. Input should be the same as above. 

### check_work_order():
gives a html-file that shoves all orders and what machines where in the order, and when they were finished. '

### makeFlowchart(string machine_nr):
Takes in a machine_nr, and generates 2 lists. The first is a list of all transitions between statuses, and the other is all transitions not happening.
Nice for making flowcharts

### Chech_freq_trans(string machine_nr):
takes in a machine, and retruns the frequency of all status-transitions in a list. 

### threshold_on_trans(machine_nr, threshold)
Takes in a machine-nr and a thershold that is the minimum frequencies of the transistions between statuses. returns a list of all transitions and frequencies as first return. It also returns the total amount of transitions used for make_markov_graphs()

### make_markov_graphs(machine_nr, threshold)
returns the list of transitions, with the precentage of frequencies/total frequencies.   

### make_dummie_table(path, machine_nr)
creates a table containing dummie variables of given machine, saves the frame at path 

### getReadings(probability, steps, machine_nr)
returns timestamps for when transistion happens with less probability than parameter. change in step is possible

### making_table(timestamp, minutes, machine_nr)
making a table given minutes before timestamp

### unique_readings(probability, steps, machine_nr, minutes)
returning 'special' readings happening before a transition

### looking_for_bugs(df)
Taking in a dataframe and returning a table with every special readings in this dataframe

### create_distribution_image(machine_nr)
making distrubution image for given machine

### find_distribution(df, lower_bound, upper_bound,machine_nr, name)
general method for making distrubution images for one column(name) in machine

### making_table_for_andrei()
finding every Statuses happening at the same time for machine M3

### finding_low_prob_andrei_table(machine_nr, prob, df) 
returning every statuses happening at the same time with a lower probability than prob

### find_unlickly_parameters(df)
finding outliers in dataframe

### creating_likely_table(machine_nr)
generating tables without outliers

### save_correct_fullframe(machine_nr)
saving frames without outliers

### finding_table_after(timestamp, minutes, machine_nr)
generating table after timestamp given minutes

### check_for_improbable_trans(machine_nr, minutes, prob)
finding low probability transactions after special readings (prob= probability of trans)

### finding_low_prob_trans(machine_nr, prob)
returning every trans as a table with lower probability than prob.

### check_csv_file()
checking if temp is as small from outliers

### create_active_table()
making active table for M3 without rotation and temperature, removed nan values, and duplicates

### creating_all_frames()
run when first cloning project, creates all fullframes

### Adding new machines :heavy_plus_sign:
Since many of the machines are different in the info they give us, the procedure for adding a new machine, could be fairly easy, if it follows the same structure, 
and gives the same sensoroutputs as one of the 4 machines made. 

### step 1:
The first thing you need to do, is put the csv files you have been given, into the Data folder udner CM4Smart->src->Data

### step 2:
Now you have to import them into the system. The way you do this, is going to the readingCSV-file, and down to the loadcsv_to_pickle method. Here there is 3 different
types. It is commented in the code, which to use where. Copy one of the lines, and type in a string being the name of the file in data-folder.

![alt text](https://github.com/anderf2706/CM4Smart/blob/master/docs/img/loadcsv.png)

**The file to change is on the bottom**

When you have set everything up here, go to Analyze_data. On line 23, change pickles(False) -> True. Do not run anything else. You will then see outputs to your console,
followed by a crash. This is normal, and isn't a problem. 

### step 3:
Go to indexing_files in Analyzer-pack, and copy one block of code as is shown here:

![alt text](https://github.com/anderf2706/CM4Smart/blob/master/docs/img/index_files.png)

**Code-snippet**

Take this codesnippet and change the name of the machine-nr first, then change the path to the files you generated using loadcsv. These are located in src->pickle_data.

### part 4:
Go to the Lists of all readings section near the bottom, looking like this:

![alt text](https://github.com/anderf2706/CM4Smart/blob/master/docs/img/list_files.png)

**Lists-section. Add one**

Add in a new list, by copying one of the existing ones, and change both names of new files in first input, second is abreviation of name, look to previous to see, 
Then third is the new machine nr.

### part 5:
This path is a little more work to get done. Becuase of the nature of the data we are given, the machines dosen't follow the same rules when it comes to structure, and what they return. This means that making a default method for indexing, is very difficult. So to add a new machine, you have to see the structure, and see if they have the same as the 4 machines already in. If they do, you have to go through index_on_month, and index_on_order and add the new machine to the right place. You have to walk through the method to add to all the places where machine-nr is used. 
If the data looks different than the machines already here, you have to add new methods. You can copy the index method already there, and use it as a template. 

### part 6:
When these methods are fixes, then you can run sort and sort_on_order. An example of this is in picture under run system at the top of this doc. When these are generated, a order folder should be found under pickle_data. If you have these files, you can start using all the other methods for manipulating the data. 


### Issue for now:
So many of the machines give different outputs, both regarding data and format, so making a standard method is not easy. 

### Prerequisites :white_check_mark:
-------------------


-pandas-profiling(need to download with conda)

numpy==1.18.5

pandas == 1.1.1

seaborn == 0.10.1

matplotlib == 3.3.1


-for installing fastai:

conda install fastai pytorch=1.0.0 -c fastai -c pytorch -c conda-forge
 
-for installing pandas-profiling:

conda install -c conda-forge pandas-profiling

## Authors :pencil2:

Anders Fredriksen and Fridtjof Høyer 
